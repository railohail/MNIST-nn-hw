{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00585384  0.03641903 -0.29968144 ...  0.33876634  0.27468906\n",
      "  -0.14427771]\n",
      " [-0.2443528  -0.32866549  0.08135715 ...  0.32054601  0.18519927\n",
      "  -0.0410405 ]\n",
      " [ 0.09031791 -0.23617362  0.08630155 ... -0.45357608  0.44292795\n",
      "  -0.42918779]\n",
      " ...\n",
      " [-0.3706507  -0.01884843  0.02850666 ...  0.10456928 -0.31105148\n",
      "  -0.24596292]\n",
      " [ 0.04507137  0.13080167 -0.36790434 ... -0.34856744 -0.15052111\n",
      "   0.30220744]\n",
      " [-0.46624793 -0.26514075  0.41162099 ...  0.0302399  -0.08481793\n",
      "   0.27250841]]\n",
      "[[ 0.43430719  0.10851007  0.07314632  0.20026877 -0.35414975  0.48978211\n",
      "   0.46705249  0.39332177 -0.29923493 -0.30296973 -0.15514075 -0.07850211\n",
      "   0.23924372  0.46573083  0.4672275   0.27483469 -0.13638132 -0.30748841\n",
      "   0.47458153 -0.13041831 -0.39445448  0.01318908  0.2780732   0.27325637\n",
      "  -0.30651523  0.08046762 -0.00878406  0.27541084  0.399376   -0.35521742\n",
      "  -0.39061459  0.22909506]\n",
      " [-0.19450606 -0.32801371 -0.38885107 -0.08243171 -0.06580933 -0.41226487\n",
      "  -0.20705009 -0.40069483  0.4198375   0.34053305 -0.05931681 -0.29090513\n",
      "  -0.20038802 -0.43720936  0.07513545 -0.20562487 -0.04038777 -0.29808066\n",
      "   0.09748223 -0.32638508  0.31297028 -0.33420978  0.34896291 -0.00771448\n",
      "  -0.27909139 -0.29740499  0.2338937   0.25211646 -0.22701654  0.48798122\n",
      "   0.2298915  -0.44568293]\n",
      " [-0.14879871 -0.32304846  0.39063533  0.20496701  0.16226449  0.34406304\n",
      "   0.28565594 -0.2945837   0.43820358  0.42438144 -0.12728641  0.33587946\n",
      "   0.35517493 -0.31115911  0.0859099   0.45043161  0.25311486 -0.10413209\n",
      "  -0.19237333 -0.32392525 -0.04301031  0.20403321 -0.02104518 -0.49915684\n",
      "   0.43680386  0.25424181  0.40281273 -0.35313023  0.04490844  0.16986463\n",
      "   0.41837665  0.33862134]\n",
      " [-0.32690201  0.4236126   0.25064308 -0.38732491  0.25680652  0.31685876\n",
      "  -0.17963864 -0.07279656 -0.2498369   0.46032732 -0.17051583 -0.18610045\n",
      "   0.08857371 -0.03432458  0.21295062  0.37704234 -0.48217449 -0.27396553\n",
      "  -0.46245844  0.34248086  0.3111342   0.25717958 -0.14399624 -0.42705063\n",
      "  -0.45502187  0.40129873  0.26606493 -0.11072056  0.28492721  0.24997621\n",
      "   0.26283733  0.14784928]\n",
      " [-0.25652208 -0.340168   -0.09579561 -0.07924072 -0.16384188 -0.49029804\n",
      "  -0.34498296 -0.19564614 -0.05008353 -0.28483912 -0.05493704  0.40614838\n",
      "   0.30656453  0.06389569 -0.35833811 -0.09038154 -0.16124165 -0.47496845\n",
      "  -0.35551568  0.1888167   0.23109534  0.28450246  0.07345616  0.0375905\n",
      "   0.49375618  0.19546791 -0.12486112 -0.0457545   0.01130066  0.36161706\n",
      "   0.45988326  0.13033215]\n",
      " [-0.44319727  0.27923805 -0.32743862 -0.37848957  0.49667865  0.26679119\n",
      "   0.20482119  0.14903133 -0.32794731  0.27329641  0.20205026  0.2472267\n",
      "  -0.39592453 -0.49376774 -0.09351109 -0.42810394  0.26338619 -0.49851354\n",
      "   0.34694594  0.13748595  0.44985762 -0.25250759 -0.44449598 -0.13956594\n",
      "   0.47638104 -0.49060626  0.21164935 -0.42317928  0.1928574  -0.49009856\n",
      "   0.01453766 -0.11093023]\n",
      " [-0.43105635  0.18001763  0.26117357 -0.49251931  0.4936707   0.49578235\n",
      "   0.18640749 -0.46409069 -0.43303889  0.28421691 -0.19288612 -0.38293894\n",
      "  -0.44121107 -0.0724736  -0.13049587  0.46625185 -0.1353612   0.01358059\n",
      "   0.25427827  0.07013985 -0.02611212 -0.41144511  0.21177564  0.22287418\n",
      "  -0.41773195 -0.04044933 -0.32162546 -0.0583695   0.45881939  0.09431281\n",
      "   0.39805544 -0.39875099]\n",
      " [ 0.28655921 -0.42839469  0.20774476 -0.38108432  0.09065372  0.28444988\n",
      "  -0.02185448 -0.34036125 -0.07625382  0.00360764  0.36905184  0.44120456\n",
      "   0.26195446  0.35489485 -0.22042298 -0.21618188  0.04160645  0.27529421\n",
      "  -0.15594235 -0.45636773 -0.27254485 -0.03100695  0.18843515  0.24760855\n",
      "   0.2205106   0.39983613 -0.24561171  0.13646022 -0.30587193 -0.48290476\n",
      "   0.48635753 -0.12779065]\n",
      " [-0.29393342 -0.48282639  0.48770447 -0.00396197  0.32166381 -0.32327687\n",
      "  -0.30669181 -0.07287003 -0.2456297  -0.16086804 -0.15286716  0.15629364\n",
      "   0.32692917 -0.32113227 -0.34102399  0.16006381  0.49560479 -0.09329092\n",
      "   0.13160026  0.14351326  0.13559424 -0.43624415  0.06078352  0.4762791\n",
      "   0.0177235   0.03483031  0.12547922 -0.36728382 -0.16941888 -0.05007629\n",
      "  -0.31796114 -0.36706371]\n",
      " [-0.20286509 -0.46670434  0.42272559  0.30876508  0.29538791  0.15247671\n",
      "   0.10660633 -0.24540439 -0.17443704  0.38806597  0.19197245 -0.10382764\n",
      "  -0.08326663  0.31246532  0.46442739 -0.07246436 -0.01640458  0.22005552\n",
      "   0.36068807  0.47523079 -0.23337302  0.09536971  0.07442307  0.4823811\n",
      "   0.18668778  0.01914613 -0.43191721 -0.31969309  0.41212073  0.36566669\n",
      "  -0.07860458 -0.20951514]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "w_i_h = weights_input_hidden = np.random.uniform(-0.5,0.5,(32,784))# the whole thing is 5 by 4 by 3 but we go by right to left (better computing) \n",
    "w_h_o = weights_hidden_output = np.random.uniform(-0.5,0.5,(10,32))\n",
    "print(w_i_h)\n",
    "print(w_h_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#bias neuron added to the hidden layer(s) and the output layer \n",
    "b_i_h = bias_input_hidden = np.zeros((32,1))\n",
    "b_h_o = bias_hidden_output = np.zeros((10,1))\n",
    "print(b_i_h)\n",
    "print(b_h_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from data import get_mnist\n",
    "images, labels = get_mnist()\n",
    "print(images.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(o_pre, gamma, beta, eps=1e-5):\n",
    "    # Compute mean and variance along the batch dimension\n",
    "    batch_mean = np.mean(o_pre, axis=0)\n",
    "    batch_var = np.var(o_pre, axis=0)\n",
    "    \n",
    "    # Normalize\n",
    "    o_norm = (o_pre - batch_mean) / np.sqrt(batch_var + eps)\n",
    "    \n",
    "    # Scale and shift\n",
    "    out = gamma * o_norm + beta\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 87.44%\n",
      "Acc: 93.18%\n",
      "Acc: 94.33%\n",
      "Acc: 94.97%\n",
      "Acc: 95.41%\n",
      "Acc: 95.79%\n",
      "Acc: 96.13%\n",
      "Acc: 96.37%\n",
      "Acc: 96.58%\n",
      "Acc: 96.79%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "nr_correct = 0\n",
    "learning_rate = 0.01\n",
    "for epoch in range(epochs):\n",
    "    for img,l in zip(images,labels):\n",
    "        img.shape += (1,)#change from 784 vector into (784,1)\n",
    "        l.shape += (1,)# change from 10 vector into (10,1)\n",
    "        \n",
    "        #forward pass \n",
    "        h_pre = b_i_h + np.dot(w_i_h,img) #bias [32,1] + weight [32,784] * image [784,1]\n",
    "        h = 1 / (1+np.exp(-h_pre)) #activation function for normalization   \n",
    "        #gamma = np.ones((h_pre.shape[0],))  # Initialize to ones nomalization\n",
    "        #beta = np.zeros((h_pre.shape[0],))\n",
    "        # h = np.maximum(0, batch_norm(h_pre,gamma,beta)) # relu\n",
    "        o_pre = b_h_o + np.dot(w_h_o,h) #bias [10,1] + weight [10,32] * image [32,1]\n",
    "        o = 1 / (1+np.exp(-o_pre)) #activation function for normalization\n",
    "        #gamma = np.ones((o_pre.shape[0],))  # Initialize to ones nomalization\n",
    "        #beta = np.zeros((o_pre.shape[0],))\n",
    "        # o = np.maximum(0, batch_norm(o_pre,gamma,beta)) # relu\n",
    "        \n",
    "        #loss function\n",
    "        e = 1/len(o)*np.sum((o-l)**2,axis=0) #MSE\n",
    "        nr_correct += int(np.argmax(o)==np.argmax(l)) #know accuracy\n",
    "\n",
    "        #backward propagation\n",
    "        delta_o = o-l #error\n",
    "        w_h_o += -learning_rate*np.dot(delta_o,np.transpose(h)) #update weight\n",
    "        b_h_o += -learning_rate*delta_o #update bias\n",
    "        delta_h = np.dot(np.transpose(w_h_o),delta_o)*(h*(1-h)) #error\n",
    "        w_i_h += -learning_rate*np.dot(delta_h,np.transpose(img)) #update weight\n",
    "        b_i_h += -learning_rate*delta_h #update bias\n",
    "    print(f\"Acc: {round((nr_correct / images.shape[0]) * 100, 2)}%\")\n",
    "    nr_correct = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rail_hail/.conda/envs/Font/lib/python3.8/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Fetch the entire dataset\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "# The last 10,000 samples are the test set\n",
    "X_test = X[-10000:]\n",
    "y_test = y[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of y test(10000,)\n",
      "the shape of X test(10000, 784)\n",
      "the shape of y test_ontshot(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to integers (they're loaded as strings)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Normalize pixel values\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "def to_one_hot(y, num_classes=10):\n",
    "    return np.eye(num_classes)[y]\n",
    "y_test_onehot = to_one_hot(y_test)\n",
    "print(f'the shape of y test{y_test.shape}')\n",
    "print(f'the shape of X test{X_test.shape}')\n",
    "print(f'the shape of y test_ontshot{y_test_onehot.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 95.73%\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "nr_correct = 0\n",
    "num = 0\n",
    "for img,l in zip(X_test,y_test_onehot):\n",
    "    num += 1\n",
    "    img.shape += (1,)#change from 784 vector into (784,1)\n",
    "    l.shape += (1,)# change from 10 vector into (10,1)\n",
    "    #forward pass \n",
    "    h_pre = b_i_h + np.dot(w_i_h,img) #bias [32,1] + weight [32,784] * image [784,1]\n",
    "    h = 1 / (1+np.exp(-h_pre)) #activation function for normalization   \n",
    "    #gamma = np.ones((h_pre.shape[0],))  # Initialize to ones nomalization\n",
    "    #beta = np.zeros((h_pre.shape[0],))\n",
    "    # h = np.maximum(0, batch_norm(h_pre,gamma,beta)) # relu\n",
    "    o_pre = b_h_o + np.dot(w_h_o,h) #bias [10,1] + weight [10,32] * image [32,1]\n",
    "    o = 1 / (1+np.exp(-o_pre)) #activation function for normalization\n",
    "    #gamma = np.ones((o_pre.shape[0],))  # Initialize to ones nomalization\n",
    "    #beta = np.zeros((o_pre.shape[0],))\n",
    "    # o = np.maximum(0, batch_norm(o_pre,gamma,beta)) # relu\n",
    "    nr_correct += int(np.argmax(o)==np.argmax(l))\n",
    "    # print(f\"Predicted: {np.argmax(o)}, Actual: {np.argmax(l)}\")\n",
    "print(f\"Acc: {round((nr_correct / X_test.shape[0]) * 100, 2)}%\")\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "# Load and preprocess a single image\n",
    "def load_and_preprocess_image(file_path):\n",
    "    with Image.open(file_path).convert('L') as img:\n",
    "        img = img.resize((28, 28))\n",
    "        img_array = np.array(img)\n",
    "        if img_array.mean() > 128:\n",
    "            img_array = 255 - img_array\n",
    "        img_array = img_array / 255.0\n",
    "        img_array = img_array.reshape(784, 1)\n",
    "    return img_array\n",
    "# Function to display the image\n",
    "def display_image(img_array):\n",
    "    plt.imshow(img_array.reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # Function to predict using your neural network\n",
    "def predict(img, w_i_h, b_i_h, w_h_o, b_h_o):\n",
    "    h_pre = b_i_h + np.dot(w_i_h, img)\n",
    "    h = 1 / (1 + np.exp(-h_pre))\n",
    "    o_pre = b_h_o + np.dot(w_h_o, h)\n",
    "    o = 1 / (1 + np.exp(-o_pre))\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the image:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main process\n",
    "folder_path = 'test'  # Change this to your image directory\n",
    "file_name = '0009.png'  # Change this to your image file name\n",
    "# Load and display the image\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "img = load_and_preprocess_image(file_path)\n",
    "\n",
    "print(\"Displaying the image:\")\n",
    "display_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Output:\n",
      "Digit 0: 0.0107\n",
      "Digit 1: 0.0001\n",
      "Digit 2: 0.5723\n",
      "Digit 3: 0.0000\n",
      "Digit 4: 0.0000\n",
      "Digit 5: 0.0004\n",
      "Digit 6: 0.0013\n",
      "Digit 7: 0.0000\n",
      "Digit 8: 0.7524\n",
      "Digit 9: 0.0011\n",
      "\n",
      "Predicted digit: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pass the image through the neural network\n",
    "output = predict(img, w_i_h, b_i_h, w_h_o, b_h_o)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nNeural Network Output:\")\n",
    "for i, prob in enumerate(output):\n",
    "    print(f\"Digit {i}: {prob[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nPredicted digit: {np.argmax(output)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Font",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
